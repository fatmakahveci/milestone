ruleorder: create_wgmlst_schema > call_allele > create_cgmlst_schema > pairwise_alignment # > sbg_aligner

configfile: "config.yaml"

import glob, os, sys
from scripts import create_reference

rule all:
	input:
		"data/"+config["reference_fasta"]

rule create_wgmlst_schema:
	input:
		genome_dir = config["genome_dir"],
		trn_file = config["training_file"],
	output:
		directory(config["schema_seed_dir"])
	message: "chewBBACA is creating whole genome MLST (wgMLST) schema."
	log: "logs/chewbbaca.log"
	threads: config["parameters"]["threads"]
	shell:
		"chewBBACA.py CreateSchema -i {input.genome_dir} -o {output} --ptf {input.trn_file} --cpu {threads}"

rule call_allele:
	input:
		genome_dir = config["genome_dir"],
		trn_file = config["training_file"],
		schema_seed_dir = config["schema_seed_dir"],
	output:
		directory(config["allele_call_dir"])
	message: "chewBBACA is calling alleles."
	log: "logs/chewbbaca.log"
	threads: config["parameters"]["threads"]
	shell:
		"chewBBACA.py AlleleCall -i {input.genome_dir} -g {input.schema_seed_dir} -o {output} --cpu {threads} --ptf {input.trn_file}"

# test call quality?

rule create_cgmlst_schema:
	input:
		allele_call_dir = config["allele_call_dir"]
	output:
		directory(config["cgmlst_dir"])
	message: "chewBBACA is creating core genome MLST (cgMLST) schema."
	log: "logs/chewbbaca.log"
	threads: config["parameters"]["threads"]
	run:
		repeated_loci = (glob.glob(f"{input.allele_call_dir}/result*/RepeatedLoci.txt"))[0]
		results_alleles_tsv = (glob.glob(f"{input.allele_call_dir}/result*/results_alleles.tsv"))[0]
		os.system(f"chewBBACA.py ExtractCgMLST -i {results_alleles_tsv} -r {repeated_loci} -p 0.95 -o {output}")

def get_cg_list(cg_schema_file):
	cg_list = []
	with open(cg_schema_file, 'r') as file:
		for line in file.readlines():
			cds = line.strip()
			cg_list.append(f"{cds}")
		file.close()
	return cg_list

rule pairwise_alignment:
	input:
		schema_seed_dir = config["schema_seed_dir"],
		cgmlst_dir = config["cgmlst_dir"]
	output:
		reference_vcf = "data/"+config["reference_vcf"],
		reference_fasta = "data/"+config["reference_fasta"]
	message: "Reference is being prepared..."
	log: "logs/reference.log"
	threads: config["parameters"]["threads"]
	run:

		cg_list = get_cg_list(f'{input.cgmlst_dir}/cgMLSTschema.txt')

		try:
			Path(f"{input.schema_seed_dir}/references").mkdir(exist_ok=True)  # create reference FASTA directory for each core gene
			Path(f"{input.schema_seed_dir}/alleles").mkdir(exist_ok=True)  # create FASTA directory for each core gene's alleles

		except OSError:
			print(f"Creation of the directories {input.schema_seed_dir}/references and {input.schema_seed_dir}/alleles are failed.")
		
		cds_to_merge_list = [] # to merge all CDSs for reference vcf

		# create reference vcf
		for cds in cg_list:
			create_reference.create_cds_vcf(f"{input.schema_seed_dir}", cds, cds_to_merge_list)

		create_reference.create_reference_vcf_fasta(f"{input.schema_seed_dir}", cds_to_merge_list, f"{output.reference_vcf}", f"{output.reference_fasta}")

		create_reference.clean_directory(f"{input.schema_seed_dir}", f"{output.reference_vcf}", f"{output.reference_fasta}")

# rule sbg_aligner:
# 	input:
# 		r1 = "data/"+config["samples"]["sample1"],
# 		r2 = "data/"+config["samples"]["sample2"],
# 		vcf = config["schema_seed_dir"]+"/"+"reference.vcf",
# 		fasta = config["schema_seed_dir"]+"/"+"reference.fasta"
# 	output:
# 		"data/"+config["samples"]["sample1"]+".bam"
# 	message: "Running SBG-aligner on {input.r1} and {input.r2}"
# 	log:
# 		"logs/assembly.log"
# 	threads:
# 		config["parameters"]["threads"]
# 	shell:
# 		"sbg-aligner -v {input.vcf} --threads {threads} --reference {input.fasta} -q {input.r1} -Q {input.r2} --read_group_library 'lib' -o {output}"

# rule sam_to_bam:
# 	input:
# 		"sample.sam"
# 	output:
# 		"sample.bam"
# 	conda:
# 		"../envs/samtools.yaml"
# 	shell:
# 		"samtools view -F 0x04 -f 0x2 -q 20 -b {input} -o {output}"

# rule bam_sort:
# 	input:
# 		"sample.bam"
# 	output:
# 		"sample.sorted.bam"
# 	conda:
# 		"../envs/samtools.yaml"
# 	shell:
# 		"samtools sort {input} -o {output}"

# rule mark_duplicates:
# 	input:
# 		"sample.sorted.bam"
# 	output:
# 		"sample.sorted.rmdup.bam"
# 	conda:
# 		"../envs/samtools.yaml"
# 	shell:
# 		"samtools collate -o - {input} | samtools fixmate -m - - "
# 		" | samtools sort -o - - | samtools markdup -r - {output}"

